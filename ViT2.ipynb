{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9maF12Uy6-hP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Y23Llg7p6-hc"
      },
      "outputs": [],
      "source": [
        "class PatchEmbedding(tf.keras.layers.Layer):                   \n",
        "    def __init__(self, size, num_of_patches, projection_dim):   \n",
        "        super().__init__()\n",
        "        self.size = size     \n",
        "        self.num_of_patches = num_of_patches + 1              \n",
        "        self.projection_dim = projection_dim   \n",
        "\n",
        "        self.projection = tf.keras.layers.Dense(projection_dim)    \n",
        "        self.clsToken = tf.Variable(initial_value=tf.keras.initializers.GlorotNormal()(shape=(1, 1, projection_dim)), trainable=True)   \n",
        "\n",
        "        self.positionEmbedding = tf.keras.layers.Embedding(self.num_of_patches, projection_dim)           \n",
        "       \n",
        "    \n",
        "    def call(self, inputs):\n",
        "        patches = tf.image.extract_patches(inputs, sizes=[1, self.size, self.size, 1],                         \n",
        "                            strides=[1, self.size, self.size, 1], rates=[1, 1, 1, 1], padding='VALID')\n",
        "        patches = tf.reshape(patches, (tf.shape(inputs)[0], -1, self.size*self.size*3))                       \n",
        "\n",
        "        patches = self.projection(patches)  \n",
        "\n",
        "        clsToken = tf.repeat(self.clsToken, repeats=tf.shape(inputs)[0],axis=0)  \n",
        "        patches = tf.concat((clsToken, patches), axis=1)            \n",
        "\n",
        "        positions = tf.range(0, self.num_of_patches, 1)[tf.newaxis,...]  \n",
        "        positionalEmbedding = self.positionEmbedding(positions)  \n",
        "        patches = patches + positionalEmbedding        \n",
        "        return patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ5sXp036-he",
        "outputId": "919fe94d-28fb-4bea-ce93-338e943cc401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 82, 128)\n"
          ]
        }
      ],
      "source": [
        "embedding = PatchEmbedding(16, 81, 128)\n",
        "result = embedding(tf.random.normal(shape=(32, 144, 144, 3)))\n",
        "print(result.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PPew7vfI6-hf"
      },
      "outputs": [],
      "source": [
        "class TransformerLayer(tf.keras.layers.Layer):    # d_model = projection_dim\n",
        "    def __init__(self, d_model, heads, mlp_rate, dropout_rate = 0.1):\n",
        "        super().__init__()\n",
        "        self.layernorm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=heads, key_dim= d_model//heads, value_dim = d_model//heads, dropout=dropout_rate)\n",
        "       \n",
        "\n",
        "        self.layernorm_2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
        "        self.mlp = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(d_model * mlp_rate, activation='gelu'),\n",
        "            tf.keras.layers.Dropout(dropout_rate),\n",
        "            tf.keras.layers.Dense(d_model, activation='gelu'),\n",
        "            tf.keras.layers.Dropout(dropout_rate)\n",
        "        ])\n",
        "\n",
        "\n",
        "    def call(self, inputs, training=True):   \n",
        "        out_1 = self.layernorm_1(inputs)\n",
        "        out_1 = self.mha(out_1,out_1, training=training)    \n",
        "        out_1 = out_1 + inputs\n",
        "\n",
        "        out_2 = self.layernorm_2(out_1)\n",
        "        out_2 = self.mlp(out_2, training=training)\n",
        "        out_2 = out_1 + out_2\n",
        "        return out_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckW6eFuz6-hg",
        "outputId": "f517d034-fd3d-490c-b01d-6afde79d302c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 82, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "transformer = TransformerLayer(128, 2, 2)\n",
        "transformer(result).shape    # transformer output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "x1pP_Dzv6-hh"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, heads, mlp_rate, num_layers=1, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.encoders = [TransformerLayer(d_model, heads, mlp_rate, dropout_rate) for _ in range(num_layers)]\n",
        "        # stacking transformer layers\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        x = inputs\n",
        "        for layer in self.encoders:\n",
        "            x = layer(x, training=training)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKcfkfc16-hh",
        "outputId": "1fba95b5-320e-4925-e00a-e6d8c6742a15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 82, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "T_E = TransformerEncoder(128, 2, 2, 4)\n",
        "T_E(result).shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2w0gA6e06-hi"
      },
      "outputs": [],
      "source": [
        "class ViT(tf.keras.Model):\n",
        "    def __init__(self, num_classes,patch_size, num_of_patches, d_model, heads, num_layers, mlp_rate, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.PatchEmbedding = PatchEmbedding(patch_size, num_of_patches, d_model)\n",
        "        self.encoder = TransformerEncoder(d_model, heads, mlp_rate, num_layers, dropout_rate)\n",
        "        self.prediction = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dropout(0.3),\n",
        "            tf.keras.layers.Dense(mlp_rate*d_model, activation='gelu'),\n",
        "            tf.keras.layers.Dropout(0.3),\n",
        "            tf.keras.layers.Dense(num_classes, activation='softmax'),\n",
        "\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        patches = self.PatchEmbedding(inputs)\n",
        "        encoderResult = self.encoder(patches, training=training)\n",
        "        clsResult = encoderResult[:, 0, :] \n",
        "        prediction = self.prediction(clsResult, training=training)\n",
        "        return prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I3-_juy6-hj",
        "outputId": "7a6d3471-4e93-40fa-fa9f-8ca0a88313f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "ViTclassifier = ViT(\n",
        "    num_classes =10,\n",
        "    patch_size=16,\n",
        "    num_of_patches = (144//16)**2,      \n",
        "    d_model=128,\n",
        "    heads=2,\n",
        "    num_layers=4,         \n",
        "    mlp_rate=2,\n",
        "    dropout_rate=0.1\n",
        ")\n",
        "\n",
        "ViTclassifier(tf.random.normal(shape=(32, 144, 144, 3))).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "EV0SOn2v6-hj"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "dEAQhd1y6-hl"
      },
      "outputs": [],
      "source": [
        "preprocessingModel = data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.Normalization(),\n",
        "    tf.keras.layers.Resizing(144, 144)\n",
        "\n",
        "])\n",
        "preprocessingModel.layers[0].adapt(x_train)   \n",
        "\n",
        "augmentaionModel =tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.RandomRotation(factor=0.2),\n",
        "    tf.keras.layers.RandomZoom(width_factor=0.2, height_factor=0.2)\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E7HGqjFK_rFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "cd0L5k0D6-hm"
      },
      "outputs": [],
      "source": [
        "def convert_to_dataset(data, batch_size, shuffle=False, augment=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "    dataset = dataset.map(lambda x, y:(preprocessingModel(x)[0],y), num_parallel_calls = tf.data.AUTOTUNE)\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(len(dataset))\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True )\n",
        "\n",
        "    if augment:\n",
        "        dataset = dataset.map(lambda x, y:(augmentaionModel(x, training=True),y), num_parallel_calls = tf.data.AUTOTUNE)\n",
        "    \n",
        "    return dataset.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m9anQuU6-hm",
        "outputId": "b7e2070c-313d-47f1-d932-251c7f708897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.97.232.90:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.97.232.90:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.97.232.90:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.97.232.90:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ],
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy0QE5h-6-hn",
        "outputId": "dbeefe1b-fb2f-455e-b1df-6a0c56ddc282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "print(strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "cwYVoaqq6-hn"
      },
      "outputs": [],
      "source": [
        "\n",
        "trainingData = convert_to_dataset(data=(x_train, y_train), batch_size=1024, shuffle=True, augment=True )\n",
        "\n",
        "valData = convert_to_dataset(data=(x_test, y_test), batch_size=1024, shuffle=True, augment=False )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "gx25lpBn6-ho"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    ViTclassifier = ViT(\n",
        "    num_classes =10,\n",
        "    patch_size=16,\n",
        "    num_of_patches = (144//16)**2,     \n",
        "    d_model=128,\n",
        "    heads=2,\n",
        "    num_layers=4,        \n",
        "    mlp_rate=2,\n",
        "    dropout_rate=0.1\n",
        ")\n",
        "\n",
        "    ViTclassifier.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
        "    optimizer= 'adam',\n",
        "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),\n",
        "                tf.keras.metrics.SparseCategoricalAccuracy(name='top_5_accuracy')\n",
        "            ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "904f-yQi6-hp",
        "outputId": "20766fd1-827c-4229-c5d4-d93d553c8410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "48/48 [==============================] - 32s 201ms/step - loss: 2.0537 - accuracy: 0.2382 - top_5_accuracy: 0.2382 - val_loss: 1.8296 - val_accuracy: 0.3176 - val_top_5_accuracy: 0.3176\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 1.8595 - accuracy: 0.3121 - top_5_accuracy: 0.3121 - val_loss: 1.7326 - val_accuracy: 0.3640 - val_top_5_accuracy: 0.3640\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 1.7754 - accuracy: 0.3490 - top_5_accuracy: 0.3490 - val_loss: 1.6613 - val_accuracy: 0.4038 - val_top_5_accuracy: 0.4038\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 10s 90ms/step - loss: 1.6984 - accuracy: 0.3800 - top_5_accuracy: 0.3800 - val_loss: 1.5598 - val_accuracy: 0.4375 - val_top_5_accuracy: 0.4375\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 11s 93ms/step - loss: 1.6370 - accuracy: 0.4084 - top_5_accuracy: 0.4084 - val_loss: 1.5049 - val_accuracy: 0.4589 - val_top_5_accuracy: 0.4589\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 1.5965 - accuracy: 0.4231 - top_5_accuracy: 0.4231 - val_loss: 1.4705 - val_accuracy: 0.4791 - val_top_5_accuracy: 0.4791\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 1.5115 - accuracy: 0.4541 - top_5_accuracy: 0.4541 - val_loss: 1.3772 - val_accuracy: 0.5027 - val_top_5_accuracy: 0.5027\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 11s 97ms/step - loss: 1.4630 - accuracy: 0.4730 - top_5_accuracy: 0.4730 - val_loss: 1.3509 - val_accuracy: 0.5145 - val_top_5_accuracy: 0.5145\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 10s 86ms/step - loss: 1.4242 - accuracy: 0.4880 - top_5_accuracy: 0.4880 - val_loss: 1.2802 - val_accuracy: 0.5319 - val_top_5_accuracy: 0.5319\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 1.3889 - accuracy: 0.5001 - top_5_accuracy: 0.5001 - val_loss: 1.2704 - val_accuracy: 0.5424 - val_top_5_accuracy: 0.5424\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 10s 93ms/step - loss: 1.3685 - accuracy: 0.5072 - top_5_accuracy: 0.5072 - val_loss: 1.2602 - val_accuracy: 0.5520 - val_top_5_accuracy: 0.5520\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 1.3213 - accuracy: 0.5255 - top_5_accuracy: 0.5255 - val_loss: 1.2120 - val_accuracy: 0.5586 - val_top_5_accuracy: 0.5586\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 1.3137 - accuracy: 0.5286 - top_5_accuracy: 0.5286 - val_loss: 1.2054 - val_accuracy: 0.5602 - val_top_5_accuracy: 0.5602\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 10s 90ms/step - loss: 1.2871 - accuracy: 0.5379 - top_5_accuracy: 0.5379 - val_loss: 1.1950 - val_accuracy: 0.5649 - val_top_5_accuracy: 0.5649\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 1.2743 - accuracy: 0.5449 - top_5_accuracy: 0.5449 - val_loss: 1.1646 - val_accuracy: 0.5738 - val_top_5_accuracy: 0.5738\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 10s 87ms/step - loss: 1.2556 - accuracy: 0.5507 - top_5_accuracy: 0.5507 - val_loss: 1.1507 - val_accuracy: 0.5842 - val_top_5_accuracy: 0.5842\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 10s 90ms/step - loss: 1.2228 - accuracy: 0.5648 - top_5_accuracy: 0.5648 - val_loss: 1.1704 - val_accuracy: 0.5745 - val_top_5_accuracy: 0.5745\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 1.2174 - accuracy: 0.5644 - top_5_accuracy: 0.5644 - val_loss: 1.1081 - val_accuracy: 0.6011 - val_top_5_accuracy: 0.6011\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 10s 90ms/step - loss: 1.1993 - accuracy: 0.5706 - top_5_accuracy: 0.5706 - val_loss: 1.1248 - val_accuracy: 0.5906 - val_top_5_accuracy: 0.5906\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 11s 104ms/step - loss: 1.1792 - accuracy: 0.5790 - top_5_accuracy: 0.5790 - val_loss: 1.0776 - val_accuracy: 0.6084 - val_top_5_accuracy: 0.6084\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 10s 87ms/step - loss: 1.1718 - accuracy: 0.5830 - top_5_accuracy: 0.5830 - val_loss: 1.0941 - val_accuracy: 0.6023 - val_top_5_accuracy: 0.6023\n",
            "Epoch 22/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 1.1639 - accuracy: 0.5841 - top_5_accuracy: 0.5841 - val_loss: 1.0842 - val_accuracy: 0.6110 - val_top_5_accuracy: 0.6110\n",
            "Epoch 23/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 1.1440 - accuracy: 0.5934 - top_5_accuracy: 0.5934 - val_loss: 1.0517 - val_accuracy: 0.6196 - val_top_5_accuracy: 0.6196\n",
            "Epoch 24/100\n",
            "48/48 [==============================] - 10s 92ms/step - loss: 1.1331 - accuracy: 0.5968 - top_5_accuracy: 0.5968 - val_loss: 1.0356 - val_accuracy: 0.6296 - val_top_5_accuracy: 0.6296\n",
            "Epoch 25/100\n",
            "48/48 [==============================] - 10s 87ms/step - loss: 1.1276 - accuracy: 0.5973 - top_5_accuracy: 0.5973 - val_loss: 1.0294 - val_accuracy: 0.6292 - val_top_5_accuracy: 0.6292\n",
            "Epoch 26/100\n",
            "48/48 [==============================] - 10s 91ms/step - loss: 1.1180 - accuracy: 0.6022 - top_5_accuracy: 0.6022 - val_loss: 1.0280 - val_accuracy: 0.6328 - val_top_5_accuracy: 0.6328\n",
            "Epoch 27/100\n",
            "48/48 [==============================] - 11s 94ms/step - loss: 1.1067 - accuracy: 0.6046 - top_5_accuracy: 0.6046 - val_loss: 1.0308 - val_accuracy: 0.6339 - val_top_5_accuracy: 0.6339\n",
            "Epoch 28/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 1.0824 - accuracy: 0.6143 - top_5_accuracy: 0.6143 - val_loss: 0.9899 - val_accuracy: 0.6468 - val_top_5_accuracy: 0.6468\n",
            "Epoch 29/100\n",
            "48/48 [==============================] - 10s 93ms/step - loss: 1.0743 - accuracy: 0.6186 - top_5_accuracy: 0.6186 - val_loss: 1.0346 - val_accuracy: 0.6281 - val_top_5_accuracy: 0.6281\n",
            "Epoch 30/100\n",
            "48/48 [==============================] - 11s 95ms/step - loss: 1.0710 - accuracy: 0.6211 - top_5_accuracy: 0.6211 - val_loss: 1.0002 - val_accuracy: 0.6408 - val_top_5_accuracy: 0.6408\n",
            "Epoch 31/100\n",
            "48/48 [==============================] - 10s 91ms/step - loss: 1.0627 - accuracy: 0.6223 - top_5_accuracy: 0.6223 - val_loss: 1.0098 - val_accuracy: 0.6426 - val_top_5_accuracy: 0.6426\n",
            "Epoch 32/100\n",
            "48/48 [==============================] - 10s 90ms/step - loss: 1.0652 - accuracy: 0.6239 - top_5_accuracy: 0.6239 - val_loss: 1.0156 - val_accuracy: 0.6343 - val_top_5_accuracy: 0.6343\n",
            "Epoch 33/100\n",
            "48/48 [==============================] - 10s 92ms/step - loss: 1.0511 - accuracy: 0.6282 - top_5_accuracy: 0.6282 - val_loss: 0.9746 - val_accuracy: 0.6512 - val_top_5_accuracy: 0.6512\n",
            "Epoch 34/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 1.0333 - accuracy: 0.6342 - top_5_accuracy: 0.6342 - val_loss: 0.9744 - val_accuracy: 0.6530 - val_top_5_accuracy: 0.6530\n",
            "Epoch 35/100\n",
            "48/48 [==============================] - 10s 92ms/step - loss: 1.0220 - accuracy: 0.6385 - top_5_accuracy: 0.6385 - val_loss: 0.9587 - val_accuracy: 0.6552 - val_top_5_accuracy: 0.6552\n",
            "Epoch 36/100\n",
            "48/48 [==============================] - 11s 93ms/step - loss: 1.0274 - accuracy: 0.6372 - top_5_accuracy: 0.6372 - val_loss: 0.9833 - val_accuracy: 0.6519 - val_top_5_accuracy: 0.6519\n",
            "Epoch 37/100\n",
            "48/48 [==============================] - 13s 141ms/step - loss: 1.0196 - accuracy: 0.6397 - top_5_accuracy: 0.6397 - val_loss: 0.9468 - val_accuracy: 0.6584 - val_top_5_accuracy: 0.6584\n",
            "Epoch 38/100\n",
            "48/48 [==============================] - 11s 110ms/step - loss: 1.0147 - accuracy: 0.6414 - top_5_accuracy: 0.6414 - val_loss: 0.9606 - val_accuracy: 0.6560 - val_top_5_accuracy: 0.6560\n",
            "Epoch 39/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 0.9957 - accuracy: 0.6480 - top_5_accuracy: 0.6480 - val_loss: 0.9227 - val_accuracy: 0.6692 - val_top_5_accuracy: 0.6692\n",
            "Epoch 40/100\n",
            "48/48 [==============================] - 10s 96ms/step - loss: 0.9840 - accuracy: 0.6523 - top_5_accuracy: 0.6523 - val_loss: 0.9363 - val_accuracy: 0.6693 - val_top_5_accuracy: 0.6693\n",
            "Epoch 41/100\n",
            "48/48 [==============================] - 10s 91ms/step - loss: 0.9787 - accuracy: 0.6536 - top_5_accuracy: 0.6536 - val_loss: 0.9342 - val_accuracy: 0.6659 - val_top_5_accuracy: 0.6659\n",
            "Epoch 42/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 0.9673 - accuracy: 0.6583 - top_5_accuracy: 0.6583 - val_loss: 0.9493 - val_accuracy: 0.6573 - val_top_5_accuracy: 0.6573\n",
            "Epoch 43/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 0.9614 - accuracy: 0.6587 - top_5_accuracy: 0.6587 - val_loss: 0.9326 - val_accuracy: 0.6685 - val_top_5_accuracy: 0.6685\n",
            "Epoch 44/100\n",
            "48/48 [==============================] - 10s 92ms/step - loss: 0.9719 - accuracy: 0.6565 - top_5_accuracy: 0.6565 - val_loss: 0.9712 - val_accuracy: 0.6638 - val_top_5_accuracy: 0.6638\n",
            "Epoch 45/100\n",
            "48/48 [==============================] - 10s 91ms/step - loss: 0.9613 - accuracy: 0.6591 - top_5_accuracy: 0.6591 - val_loss: 0.9100 - val_accuracy: 0.6736 - val_top_5_accuracy: 0.6736\n",
            "Epoch 46/100\n",
            "48/48 [==============================] - 11s 94ms/step - loss: 0.9503 - accuracy: 0.6629 - top_5_accuracy: 0.6629 - val_loss: 0.9164 - val_accuracy: 0.6765 - val_top_5_accuracy: 0.6765\n",
            "Epoch 47/100\n",
            "48/48 [==============================] - 11s 95ms/step - loss: 0.9347 - accuracy: 0.6697 - top_5_accuracy: 0.6697 - val_loss: 0.9166 - val_accuracy: 0.6753 - val_top_5_accuracy: 0.6753\n",
            "Epoch 48/100\n",
            "48/48 [==============================] - 10s 91ms/step - loss: 0.9406 - accuracy: 0.6673 - top_5_accuracy: 0.6673 - val_loss: 0.8966 - val_accuracy: 0.6846 - val_top_5_accuracy: 0.6846\n",
            "Epoch 49/100\n",
            "48/48 [==============================] - 11s 99ms/step - loss: 0.9269 - accuracy: 0.6713 - top_5_accuracy: 0.6713 - val_loss: 0.8911 - val_accuracy: 0.6815 - val_top_5_accuracy: 0.6815\n",
            "Epoch 50/100\n",
            "48/48 [==============================] - 10s 92ms/step - loss: 0.9158 - accuracy: 0.6786 - top_5_accuracy: 0.6786 - val_loss: 0.8954 - val_accuracy: 0.6833 - val_top_5_accuracy: 0.6833\n",
            "Epoch 51/100\n",
            "48/48 [==============================] - 10s 90ms/step - loss: 0.9236 - accuracy: 0.6725 - top_5_accuracy: 0.6725 - val_loss: 0.9224 - val_accuracy: 0.6790 - val_top_5_accuracy: 0.6790\n",
            "Epoch 52/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 0.9156 - accuracy: 0.6783 - top_5_accuracy: 0.6783 - val_loss: 0.8849 - val_accuracy: 0.6957 - val_top_5_accuracy: 0.6957\n",
            "Epoch 53/100\n",
            "48/48 [==============================] - 11s 93ms/step - loss: 0.9058 - accuracy: 0.6795 - top_5_accuracy: 0.6795 - val_loss: 0.9179 - val_accuracy: 0.6757 - val_top_5_accuracy: 0.6757\n",
            "Epoch 54/100\n",
            "48/48 [==============================] - 10s 93ms/step - loss: 0.9004 - accuracy: 0.6811 - top_5_accuracy: 0.6811 - val_loss: 0.8813 - val_accuracy: 0.6905 - val_top_5_accuracy: 0.6905\n",
            "Epoch 55/100\n",
            "48/48 [==============================] - 11s 91ms/step - loss: 0.9021 - accuracy: 0.6813 - top_5_accuracy: 0.6813 - val_loss: 0.8790 - val_accuracy: 0.6913 - val_top_5_accuracy: 0.6913\n",
            "Epoch 56/100\n",
            "48/48 [==============================] - 10s 87ms/step - loss: 0.8852 - accuracy: 0.6866 - top_5_accuracy: 0.6866 - val_loss: 0.8970 - val_accuracy: 0.6867 - val_top_5_accuracy: 0.6867\n",
            "Epoch 57/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 0.8796 - accuracy: 0.6901 - top_5_accuracy: 0.6901 - val_loss: 0.8787 - val_accuracy: 0.6906 - val_top_5_accuracy: 0.6906\n",
            "Epoch 58/100\n",
            "48/48 [==============================] - 11s 93ms/step - loss: 0.8786 - accuracy: 0.6906 - top_5_accuracy: 0.6906 - val_loss: 0.8983 - val_accuracy: 0.6877 - val_top_5_accuracy: 0.6877\n",
            "Epoch 59/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 0.8753 - accuracy: 0.6917 - top_5_accuracy: 0.6917 - val_loss: 0.8927 - val_accuracy: 0.6870 - val_top_5_accuracy: 0.6870\n",
            "Epoch 60/100\n",
            "48/48 [==============================] - 10s 87ms/step - loss: 0.8742 - accuracy: 0.6915 - top_5_accuracy: 0.6915 - val_loss: 0.8858 - val_accuracy: 0.6916 - val_top_5_accuracy: 0.6916\n",
            "Epoch 61/100\n",
            "48/48 [==============================] - 11s 109ms/step - loss: 0.8600 - accuracy: 0.6953 - top_5_accuracy: 0.6953 - val_loss: 0.8858 - val_accuracy: 0.6939 - val_top_5_accuracy: 0.6939\n",
            "Epoch 62/100\n",
            "48/48 [==============================] - 11s 90ms/step - loss: 0.8591 - accuracy: 0.6991 - top_5_accuracy: 0.6991 - val_loss: 0.8884 - val_accuracy: 0.6919 - val_top_5_accuracy: 0.6919\n",
            "Epoch 63/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 0.8627 - accuracy: 0.6959 - top_5_accuracy: 0.6959 - val_loss: 0.8733 - val_accuracy: 0.6925 - val_top_5_accuracy: 0.6925\n",
            "Epoch 64/100\n",
            "48/48 [==============================] - 10s 91ms/step - loss: 0.8470 - accuracy: 0.7005 - top_5_accuracy: 0.7005 - val_loss: 0.8540 - val_accuracy: 0.6979 - val_top_5_accuracy: 0.6979\n",
            "Epoch 65/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 0.8461 - accuracy: 0.7013 - top_5_accuracy: 0.7013 - val_loss: 0.8819 - val_accuracy: 0.6942 - val_top_5_accuracy: 0.6942\n",
            "Epoch 66/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 0.8339 - accuracy: 0.7062 - top_5_accuracy: 0.7062 - val_loss: 0.8556 - val_accuracy: 0.7017 - val_top_5_accuracy: 0.7017\n",
            "Epoch 67/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 0.8303 - accuracy: 0.7058 - top_5_accuracy: 0.7058 - val_loss: 0.8691 - val_accuracy: 0.7010 - val_top_5_accuracy: 0.7010\n",
            "Epoch 68/100\n",
            "48/48 [==============================] - 10s 86ms/step - loss: 0.8376 - accuracy: 0.7056 - top_5_accuracy: 0.7056 - val_loss: 0.8663 - val_accuracy: 0.6975 - val_top_5_accuracy: 0.6975\n",
            "Epoch 69/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 0.8301 - accuracy: 0.7068 - top_5_accuracy: 0.7068 - val_loss: 0.8573 - val_accuracy: 0.6961 - val_top_5_accuracy: 0.6961\n",
            "Epoch 70/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 0.8213 - accuracy: 0.7088 - top_5_accuracy: 0.7088 - val_loss: 0.8589 - val_accuracy: 0.7031 - val_top_5_accuracy: 0.7031\n",
            "Epoch 71/100\n",
            "48/48 [==============================] - 11s 105ms/step - loss: 0.8168 - accuracy: 0.7125 - top_5_accuracy: 0.7125 - val_loss: 0.8565 - val_accuracy: 0.6992 - val_top_5_accuracy: 0.6992\n",
            "Epoch 72/100\n",
            "48/48 [==============================] - 11s 103ms/step - loss: 0.8221 - accuracy: 0.7099 - top_5_accuracy: 0.7099 - val_loss: 0.8573 - val_accuracy: 0.7055 - val_top_5_accuracy: 0.7055\n",
            "Epoch 73/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 0.8189 - accuracy: 0.7103 - top_5_accuracy: 0.7103 - val_loss: 0.8595 - val_accuracy: 0.6968 - val_top_5_accuracy: 0.6968\n",
            "Epoch 74/100\n",
            "48/48 [==============================] - 10s 92ms/step - loss: 0.7962 - accuracy: 0.7177 - top_5_accuracy: 0.7177 - val_loss: 0.8653 - val_accuracy: 0.6995 - val_top_5_accuracy: 0.6995\n",
            "Epoch 75/100\n",
            "48/48 [==============================] - 11s 92ms/step - loss: 0.7968 - accuracy: 0.7192 - top_5_accuracy: 0.7192 - val_loss: 0.8765 - val_accuracy: 0.7011 - val_top_5_accuracy: 0.7011\n",
            "Epoch 76/100\n",
            "48/48 [==============================] - 10s 86ms/step - loss: 0.7966 - accuracy: 0.7188 - top_5_accuracy: 0.7188 - val_loss: 0.8417 - val_accuracy: 0.7082 - val_top_5_accuracy: 0.7082\n",
            "Epoch 77/100\n",
            "48/48 [==============================] - 10s 87ms/step - loss: 0.7914 - accuracy: 0.7222 - top_5_accuracy: 0.7222 - val_loss: 0.8765 - val_accuracy: 0.7006 - val_top_5_accuracy: 0.7006\n",
            "Epoch 78/100\n",
            "48/48 [==============================] - 10s 85ms/step - loss: 0.7813 - accuracy: 0.7236 - top_5_accuracy: 0.7236 - val_loss: 0.8487 - val_accuracy: 0.7131 - val_top_5_accuracy: 0.7131\n",
            "Epoch 79/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 0.7898 - accuracy: 0.7211 - top_5_accuracy: 0.7211 - val_loss: 0.8822 - val_accuracy: 0.6959 - val_top_5_accuracy: 0.6959\n",
            "Epoch 80/100\n",
            "48/48 [==============================] - 10s 87ms/step - loss: 0.7805 - accuracy: 0.7269 - top_5_accuracy: 0.7269 - val_loss: 0.8449 - val_accuracy: 0.7041 - val_top_5_accuracy: 0.7041\n",
            "Epoch 81/100\n",
            "48/48 [==============================] - 10s 86ms/step - loss: 0.7812 - accuracy: 0.7245 - top_5_accuracy: 0.7245 - val_loss: 0.8535 - val_accuracy: 0.7084 - val_top_5_accuracy: 0.7084\n",
            "Epoch 82/100\n",
            "48/48 [==============================] - 11s 102ms/step - loss: 0.7795 - accuracy: 0.7234 - top_5_accuracy: 0.7234 - val_loss: 0.8370 - val_accuracy: 0.7106 - val_top_5_accuracy: 0.7106\n",
            "Epoch 83/100\n",
            "48/48 [==============================] - 11s 92ms/step - loss: 0.7708 - accuracy: 0.7283 - top_5_accuracy: 0.7283 - val_loss: 0.8472 - val_accuracy: 0.7094 - val_top_5_accuracy: 0.7094\n",
            "Epoch 84/100\n",
            "48/48 [==============================] - 11s 92ms/step - loss: 0.7643 - accuracy: 0.7310 - top_5_accuracy: 0.7310 - val_loss: 0.8543 - val_accuracy: 0.7099 - val_top_5_accuracy: 0.7099\n",
            "Epoch 85/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 0.7717 - accuracy: 0.7287 - top_5_accuracy: 0.7287 - val_loss: 0.8374 - val_accuracy: 0.7142 - val_top_5_accuracy: 0.7142\n",
            "Epoch 86/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 0.7637 - accuracy: 0.7313 - top_5_accuracy: 0.7313 - val_loss: 0.8500 - val_accuracy: 0.7092 - val_top_5_accuracy: 0.7092\n",
            "Epoch 87/100\n",
            "48/48 [==============================] - 10s 89ms/step - loss: 0.7524 - accuracy: 0.7340 - top_5_accuracy: 0.7340 - val_loss: 0.8533 - val_accuracy: 0.7048 - val_top_5_accuracy: 0.7048\n",
            "Epoch 88/100\n",
            "48/48 [==============================] - 11s 94ms/step - loss: 0.7476 - accuracy: 0.7361 - top_5_accuracy: 0.7361 - val_loss: 0.8303 - val_accuracy: 0.7183 - val_top_5_accuracy: 0.7183\n",
            "Epoch 89/100\n",
            "48/48 [==============================] - 10s 87ms/step - loss: 0.7487 - accuracy: 0.7358 - top_5_accuracy: 0.7358 - val_loss: 0.8485 - val_accuracy: 0.7121 - val_top_5_accuracy: 0.7121\n",
            "Epoch 90/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 0.7371 - accuracy: 0.7391 - top_5_accuracy: 0.7391 - val_loss: 0.8370 - val_accuracy: 0.7157 - val_top_5_accuracy: 0.7157\n",
            "Epoch 91/100\n",
            "48/48 [==============================] - 10s 86ms/step - loss: 0.7362 - accuracy: 0.7412 - top_5_accuracy: 0.7412 - val_loss: 0.8507 - val_accuracy: 0.7108 - val_top_5_accuracy: 0.7108\n",
            "Epoch 92/100\n",
            "48/48 [==============================] - 11s 102ms/step - loss: 0.7241 - accuracy: 0.7431 - top_5_accuracy: 0.7431 - val_loss: 0.8415 - val_accuracy: 0.7165 - val_top_5_accuracy: 0.7165\n",
            "Epoch 93/100\n",
            "48/48 [==============================] - 10s 92ms/step - loss: 0.7343 - accuracy: 0.7418 - top_5_accuracy: 0.7418 - val_loss: 0.8397 - val_accuracy: 0.7143 - val_top_5_accuracy: 0.7143\n",
            "Epoch 94/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 0.7223 - accuracy: 0.7464 - top_5_accuracy: 0.7464 - val_loss: 0.8305 - val_accuracy: 0.7119 - val_top_5_accuracy: 0.7119\n",
            "Epoch 95/100\n",
            "48/48 [==============================] - 10s 87ms/step - loss: 0.7209 - accuracy: 0.7464 - top_5_accuracy: 0.7464 - val_loss: 0.8249 - val_accuracy: 0.7185 - val_top_5_accuracy: 0.7185\n",
            "Epoch 96/100\n",
            "48/48 [==============================] - 11s 96ms/step - loss: 0.7189 - accuracy: 0.7459 - top_5_accuracy: 0.7459 - val_loss: 0.8368 - val_accuracy: 0.7123 - val_top_5_accuracy: 0.7123\n",
            "Epoch 97/100\n",
            "48/48 [==============================] - 10s 90ms/step - loss: 0.7188 - accuracy: 0.7464 - top_5_accuracy: 0.7464 - val_loss: 0.8578 - val_accuracy: 0.7070 - val_top_5_accuracy: 0.7070\n",
            "Epoch 98/100\n",
            "48/48 [==============================] - 10s 84ms/step - loss: 0.7178 - accuracy: 0.7478 - top_5_accuracy: 0.7478 - val_loss: 0.8262 - val_accuracy: 0.7148 - val_top_5_accuracy: 0.7148\n",
            "Epoch 99/100\n",
            "48/48 [==============================] - 10s 86ms/step - loss: 0.7096 - accuracy: 0.7497 - top_5_accuracy: 0.7497 - val_loss: 0.8681 - val_accuracy: 0.7094 - val_top_5_accuracy: 0.7094\n",
            "Epoch 100/100\n",
            "48/48 [==============================] - 10s 88ms/step - loss: 0.7050 - accuracy: 0.7523 - top_5_accuracy: 0.7523 - val_loss: 0.8338 - val_accuracy: 0.7195 - val_top_5_accuracy: 0.7195\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f087051bd10>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "ViTclassifier.fit(x = trainingData, validation_data=valData, batch_size=1024, epochs = 100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ViTclassifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6DfO7v6_t13",
        "outputId": "e3ba3145-a7f8-4d8b-9194-3d9fdec4f80b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vi_t_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " patch_embedding_6 (PatchEmb  multiple                 109056    \n",
            " edding)                                                         \n",
            "                                                                 \n",
            " transformer_encoder_6 (Tran  multiple                 529920    \n",
            " sformerEncoder)                                                 \n",
            "                                                                 \n",
            " sequential_38 (Sequential)  (128, 10)                 35594     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 674,570\n",
            "Trainable params: 674,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDC9jTyJDS4Y",
        "outputId": "d4eae4e6-7d9e-4208-8d17-3776d5eccb89"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote add origin https://github.com/Ali-1329/ViT.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq1-_5IvC1vA",
        "outputId": "335f8235-8ffe-4b72-9a7f-d891cb1ebcad"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: remote origin already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add README.md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9Jy89RcC60C",
        "outputId": "c0467403-199e-4e8a-b4d5-85165a620451"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: pathspec 'README.md' did not match any files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email 'jafariali1329@gmail.com'"
      ],
      "metadata": {
        "id": "K8FtcQ-XEJGm"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pX1hvPpIEfIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add  *"
      ],
      "metadata": {
        "id": "03Hidcb3EAfv"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m 'first commit'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "119I1wMqEf9E",
        "outputId": "da8531bc-4c16-46ce-9d79-0310f2805057"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[master (root-commit) 4e95507] first commit\n",
            " 6 files changed, 50070 insertions(+)\n",
            " create mode 100755 sample_data/README.md\n",
            " create mode 100755 sample_data/anscombe.json\n",
            " create mode 100644 sample_data/california_housing_test.csv\n",
            " create mode 100644 sample_data/california_housing_train.csv\n",
            " create mode 100644 sample_data/mnist_test.csv\n",
            " create mode 100644 sample_data/mnist_train_small.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "ViT.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}